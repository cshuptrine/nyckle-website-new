<!DOCTYPE html>
<html lang="en">
<head>

<!--Meta Tags & Codes -->
<!--- General Meta -->
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>

<!-- For Modern Browsers -->
<link rel="icon" href="/favicon.svg" type="image/svg+xml">

<!-- For older browsers -->
<link rel="icon" sizes="16x16 32x32" type="image/x-icon" href="/favicon.ico">

<!-- For Android & Chrome fallback -->
<link rel="icon" type="image/png" sizes="192x192" href="/favicon-192x192.png">

<!-- For iOS Touch Screens-->
<link rel="apple-touch-icon" sizes="180x180" type="image/png" href="/apple-touch-icon.png">

<!-- For Windows Start Screen -->
<meta name="msapplication-TileImage" type="image/png" sizes="144x144" content="/mstile-144x144.png">
<meta name="msapplication-TileColor" content="#0b2436">


<title>Computer Vision SaaS Landscape: Comparison of the Top 9 Players</title>


<link rel="canonical" href="https://www.nyckel.com/blog/computer-vision-saas-landscape-comparison-of-the-top-9-players/"/>
<link rel="alternate" href="https://www.nyckel.com/blog/computer-vision-saas-landscape-comparison-of-the-top-9-players/" hreflang="x-default" />
<meta property="og:url" content="https://www.nyckel.com/blog/computer-vision-saas-landscape-comparison-of-the-top-9-players/"/>


<meta name="description" content=" We compare nine leading computer vision SaaS providers on functionality, model creation time, performance, market positioning, and pricing. "/>
<meta name="google-site-verification" content="D1Sb_HlWxKALYtw5gfg6yqEdCgS8w4F8sIk1scf_gFo"/>
<link rel="alternate" href="https://www.nyckel.com/blog/feed.xml" type="application/rss+xml" title="Nyckel - RSS"/> 

<!--- OpenGraph -->
<meta property="og:title" content="Computer Vision SaaS Landscape: Comparison of the Top 9 Players"/>
<meta property="og:description" content="We compare nine leading computer vision SaaS providers on functionality, model creation time, performance, market positioning, and pricing."/>

  <meta property="og:image" content="https://www.nyckel.com/blog/images/computer-vision-landscape.webp"/>


<meta property="og:image:width" content="800"/>
<meta property="og:image:height" content="400"/>

<meta property="og:site_name" content="Nyckel"/>


<!--- Robots -->
<meta name="robots" content="max-image-preview:large"/>


<!--- Schemas -->

<script type="application/ld+json">{"@context":"https://schema.org","@type":"Organization","name":"Nyckel","legalName":"Nyckel","url":"https://www.nyckel.com/","@id":"nyckel.com/#organization","logo":"https://www.discoverablemarketing.com/assets/images/important/DiscoverableLogo_Color_240.png","foundingDate":"2020","founders":[{"@type":"Person","name":"Dan Ott"}],"contactPoint":{"@type":"ContactPoint","contactType":"customer support","email":"feedback@nyckel.com","url":"https://www.nyckel.com/contact/"}}</script>
<script type="application/ld+json">{"@context":"https://schema.org","@type":"LocalBusiness","name":"Nyckel","image":"https://www.discoverablemarketing.com/assets/images/important/DiscoverableLogo_Color_240.png","url":"https://www.nyckel.com/","@id":"nyckel.com/#organization","telephone":"434-444-2268","openingHoursSpecification":{"@type":"OpeningHoursSpecification","dayOfWeek":["Monday","Tuesday","Wednesday","Thursday","Friday"],"opens":"09:00","closes":"17:30"}}</script>


  <meta property="og:type" content="article"/>
  <meta property="article:author" content="john"/>
  <meta property="article:modified_time" content=""/>
  <meta property="article:published_time" content="2023-05-17 00:00:00 -0400"/>
  <!--- BlogPosting --->
  <script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"john"},"dateModified":"","datePublished":"2023-05-17 00:00:00 -0400","headline":"Computer Vision SaaS Landscape: Comparison of the Top 9 Players","mainEntityOfPage":{"@id":"https://www.nyckel.com/blog/computer-vision-saas-landscape-comparison-of-the-top-9-players/","@type":"itemPage","url":"https://www.nyckel.com/blog/computer-vision-saas-landscape-comparison-of-the-top-9-players/"},"description":"We compare nine leading computer vision SaaS providers on functionality, model creation time, performance, market positioning, and pricing.","url":"https://www.nyckel.com/blog/computer-vision-saas-landscape-comparison-of-the-top-9-players/","image":{"@type":"ImageObject","url":"https://www.nyckel.com","width":"400","height":"800"},"publisher":{"@type":"Organization","name":"Nyckel","url":"https://www.nyckel.com/"}}</script>
  

  
  <!--- ImageObject --->
  <script type="application/ld+json">{"@context":"https://schema.org/","@type":"ImageObject","contentUrl":"https://www.nyckel.com/blog/images/computer-vision-landscape.webp", "acquireLicensePage":"https://www.nyckel.com/contact/","license":"https://www.nyckel.com/contact/", "copyrightNotice": "Nyckel","caption":"We compare nine leading computer vision SaaS providers on functionality, model creation time, performance, market positioning, and pricing.","creditText":"Nyckel","creator":{"@type":"Organization","name":"Nyckel"}}</script>
  





<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-191564533-1">
</script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    const gaMeasurementID = 'UA-191564533-1';
    gtag('config', gaMeasurementID, {'linker': {'domains': ['www.nyckel.com', 'login.nyckel.com', 'try.nyckel.com']}});

    window.pageChange = (path) => {
        gtag('config', gaMeasurementID, { 'page_path': path });
    }
</script>


<!-- Google Tag Manager -->
<script defer>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WXH98NF7');</script>
<!-- End Google Tag Manager -->

  

<script>
  window.dataLayer = window.dataLayer || [];

  function loadGTM() {
    (function(w, d, s, l, i) {
      w[l] = w[l] || [];
      w[l].push({ 'gtm.start': new Date().getTime(), event: 'gtm.js' });
      var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s),
        dl = l != 'dataLayer' ? '&l=' + l : '';
      j.async = true;
      j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
      f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-NL7KWX59');
  }

  function lazyLoadGTM() {
    window.removeEventListener('scroll', lazyLoadGTM);
    loadGTM();
  }

  window.addEventListener('scroll', lazyLoadGTM);
</script>

<script>
    document.addEventListener('DOMContentLoaded', function() {
        var image = document.querySelector('.hero-image');

        // Define the breakpoint for mobile devices (e.g., 768px for tablets)
        var mobileBreakpoint = 768;

        // Check if the screen width is less than or equal to the breakpoint
        if (window.innerWidth <= mobileBreakpoint) {
            // It's a mobile device, so add the lazy loading attribute
            image.setAttribute('loading', 'lazy');
        }
    });
</script>

<!--SCSS -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--Toggled -->

  
</head>

<body >
  
<nav
  class="navbar  absolute nav-uppercase  navbar-hover-opacity navbar-expand-lg">
  <div
    class=" container  flex-row justify-content-center">
    <div class="navbar-brand">
      <a href="/">

        
        <img src="/Nyckel-Logo.png"
         class=" logo-dark  "
          alt="Nyckel logo" width="956" height="180"/>
      </a>
    </div>
    <div class="navbar-other ml-auto order-lg-3">
      <ul class="navbar-nav flex-row align-items-center" data-sm-skip="true">
        <li class="nav-item">
          <div class="navbar-hamburger d-lg-none d-xl-none ml-auto"><button class="hamburger animate plain" data-toggle="offcanvas-nav"><span></span></button></div>
        </li>
        <li class="nav-item d-none d-lg-block pl-0" style="padding-right:2%"><a href="/contact/" class="btn m-0" style="background-color:#306fa2;">Contact</a></li>
       <li class="nav-item d-none d-lg-block pl-0"><a href="https://www.nyckel.com/console" class="btn m-0" style="background-color:#e7a83d">Free Sign-Up</a></li>
      </ul>
      <!-- /.navbar-nav -->
    </div>
    <!-- /.navbar-other -->

    <div class="navbar-collapse offcanvas-nav">
      <div class="offcanvas-header d-lg-none d-xl-none">
        <a href="/">
          <img src="/nyckel-white-color.png" class="logo-light" alt="Nyckel logo" width="956" height="180" loading="lazy"/></a>
        <button class="plain offcanvas-close offcanvas-nav-close"><i class="jam jam-close"></i></button>
      </div>
      <ul class="navbar-nav mx-auto">
        
        
        
        <li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="/pricing/">Pricing</a>
        </li>
        
        
        
        
        <li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="/customers/">Customers</a>
        </li>
        
        
        
        
        <li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="/about/">About</a>
        </li>
        
        
        
        
        <li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="/blog/">Blog</a>
        </li>
        
        
        
        
        <li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="https://www.nyckel.com/docs">API Docs</a>
        </li>
        
        
      </ul>
      <!-- /.navbar-nav -->
    </div>
    <!-- /.navbar-collapse -->
  </div>
  <!-- /.container -->
</nav>

<!--<div class="post-font2 post-font">-->
<div class="content-wrapper">
<div class="wrapper white-wrapper">
    <div class="row">
    </div></div>
        <div id="main" role="main" class="readingpane">
<article class="post">

  
  <div class="hero hero2">
    <div class="hero-contents hero-contents2 contain-1200 p-mobile-1350 d-flex">
      <div class="title-area d-flex flex-column justify-content-between">
        <div>
          <h1 style="font-size: 0.6em;">Computer Vision SaaS Landscape: Comparison of the Top 9 Players</h1>
          <div class="summary">We compare nine leading computer vision SaaS providers on functionality, model creation time, performance, market positioning, and pricing.</div>
        </div>

        
        
        <div class="author">
          <div class="author-area">
            
            <span class="author-name">John Weston</span>
            
            
            
            
            <a href="https://linkedin.com/in/john-weston" target="_blank">
              <i class="fa fa-linkedin fa-lg social-icon"></i>
            </a>
            
            
          </div>
          <span class="date">
            Posted May 2023
          </span>
        </div>
        
      </div>
      
      <div class="image-area">
        <img src="/blog/images/computer-vision-landscape.webp" alt="" />
      </div>
      
    </div>
  </div>

  <div class="entry">
    <p><em>To maintain as objective of an assessment as possible, we hired a freelance writer, <a href="https://www.linkedin.com/in/john-weston/">John Weston</a>, who did not have prior experience using Nyckel and does not have ML expertise to test the computer vision platforms featured in this post.</em></p>

<p>As your company grows, chances are you will be looking to automate some of your image processing. For example, you may want to count items in images, review the presence or absence of particular objects, identify the category of certain objects, or complete some other task related to your images.</p>

<p>Such automation requires machine learning (ML). Building an ML system yourself can be tempting, but it’s often <a href="https://www.nyckel.com/blog/ml-too-hard-for-software-developers/">far too challenging</a>, wastes time, and ties up labor. We see so many businesses putting off implementing ML until the pain of manual operations becomes unbearable.</p>

<p>The good news is that there are many computer vision SaaS solutions out there, ready to manage your visual data, apply various ML techniques to it, and deploy your ML outputs back into your products and systems. But how do you choose the best SaaS solution for your business in such a crowded field?</p>

<p>To help you understand your options, we reviewed the 9 leading computer vision SaaS players. We compared their functionality, market positioning, and pricing. We also completed a custom <a href="https://www.nyckel.com/blog/image-classification-benchmark-google-vs-aws-vs-hugging-face-vs-nyckel/">image classification benchmarking</a> task (<em>does this image show a person wearing a face mask correctly, incorrectly, or not at all?</em>) using novel data to compare the platforms’ performance and user experience.</p>

<p>Before we review how the 9 providers fared with this task, let’s talk a bit about how we chose them.</p>

<h2 id="how-did-we-pick-these-9-computer-vision-saas-players">How did we pick these 9 computer vision SaaS players?</h2>

<p>The landscape of computer vision SaaS is both dense and sprawling. For example, AWS Sagemaker could be considered a computer vision SaaS platform. However, it’s so broad and general that it is really more of an ecosystem, with a correspondingly steep learning curve. For the purpose of this article, we focus on platforms that are:</p>

<ol>
  <li><strong>Self-service:</strong> They include open access, transparent pricing, and API documentation.</li>
  <li><strong>No machine learning skills required:</strong> For example, they don’t ask you to pick a particular network architecture.</li>
  <li><strong>Full-stack:</strong> The service should provide data annotation, AutoML (training), and deploy functionality. All you should need is some data, and there’s no need for additional software or programming.</li>
</ol>

<p>We initially identified 11 CV service providers, including 8 startups, as well as 3 behemoths that offer specialized computer vision services that are more or less self-contained within their ecosystems:</p>

<ul>
  <li><a href="#nyckel">Nyckel</a></li>
  <li><a href="#ximilar">Ximilar</a></li>
  <li><a href="#roboflow">Roboflow</a></li>
  <li><a href="#hasty">Hasty</a></li>
  <li><a href="#levity">Levity</a></li>
  <li><a href="#clarifai">Clarifai</a></li>
  <li><a href="#google-vertex-ai">Google Vertex AI</a></li>
  <li><a href="#azure-custom-vision">Azure Custom Vision</a></li>
  <li><a href="#aws-rekognition-custom-labels">AWS Rekognition Custom Labels</a></li>
  <li><a href="#imagga">Imagga</a>*</li>
  <li><a href="#datature">Datature</a>*</li>
</ul>

<p>*We learned that neither Imagga nor Datature are “full-stack” in the sense we use it in this survey. While both platforms allow users to train a custom model to classify image data, Imagga requires the use of a command line interface for image data upload, and then trains a bespoke model for you. Datature allows you to go further through its UI, allowing data upload and annotation as well as model training. Datature’s model deployment step, however, requires the use of separate software. For these reasons, we removed these two startups from further consideration in the rest of this survey.</p>

<p>Now let’s take a look at the criteria we used to compare the nine players.</p>

<h2 id="how-we-compared-the-computer-vision-service-providers">How we compared the computer vision service providers</h2>

<p>In this survey of the top computer vision players, we focused criteria that are important for users who are relatively new to using <a href="https://www.nyckel.com/blog/guide-to-computer-vision-for-non-ml-experts/">machine learning to solve computer vision problems</a>. Here’s the list of what we used for evaluation criteria:</p>

<ol>
  <li><strong>Functionality.</strong> What types of computer vision problems can you solve with the platform?</li>
  <li><strong>Time to first model.</strong> How long did it take from the time we created an account until we classified the first image with our newly-trained model?</li>
  <li><strong>Performance.</strong> Does the trained model work using a few simple images? We’ll run a benchmarking test for each platform to check their performance.</li>
  <li><strong>Market positioning.</strong> How does the company market itself? For example, does it focus on “task automation?” Is the product designed “for developers?”</li>
  <li><strong>Pricing.</strong> How does the company structure its pricing? What does it charge for?</li>
</ol>

<p>Now we have a list of CV SaaS players and a list of criteria to use to compare them. Let’s now run through the benchmarking task.</p>

<h2 id="introducing-our-computer-vision-benchmarking-task">Introducing our computer vision benchmarking task</h2>

<p>Our dataset included a set of 76 images sourced from Google. The images fall into three categories: wearing a mask correctly (n = 20), wearing a mask incorrectly (n = 32), and not wearing a mask (n = 24).</p>

<figure class="figure">

    

    

    

    
        <div class="post-img">
        <!-- Add the 'boxed' class if 'box' attribute is 'yes' -->
        <img src="../images/mask.webp" alt="The images fall into three categories: wearing a mask correctly, wearing a mask incorrectly, and not wearing a mask" class=" " style="border-radius: 20px; max-width: 100%" srcset="../images/mask.webp 2x%" loading="lazy" />
    </div>
    <figcaption></figcaption>
        

</figure>

<p>We initially started with a smaller set of images, but one of the platforms (Ximilar) required a minimum of 20 images per class. So, we adjusted the dataset for all providers.</p>

<p>For each platform, we looked for the fastest way to train a custom classifier using these images. The basic process was to upload the training data, label it, train a model using the training data, and then test the model on 7 images. (Note: Hasty didn’t have an image classification option — at least in its free plan — so we used object detection.)</p>

<h2 id="comparison-results-how-do-the-computer-vision-saas-services-stack-up">Comparison results: How do the computer vision SaaS services stack up?</h2>

<p>This table summarizes what we found for the 9 chosen providers.</p>

<div class="table-wrapper" markdown="block"><table>
  <thead>
    <tr>
      <th><strong>Platform</strong></th>
      <th><strong>Functionality</strong></th>
      <th><strong>Time to first model</strong></th>
      <th><strong>Performance</strong></th>
      <th><strong>Positioning</strong></th>
      <th><strong>Pricing</strong> (as of March 2023)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="#nyckel">Nyckel</a></td>
      <td>Image classification, image tagging, semantic image search, object detection</td>
      <td>✅ <strong>A few minutes.</strong> Create an account via Google in one click; seconds or minutes to import data; first model ready within minutes.</td>
      <td>✅ 7/7 correct</td>
      <td>“Lightning fast machine learning for developers.” Caters to small to midsize companies without in-house ML expertise that need to automate to achieve rapid growth. No ML knowledge required.</td>
      <td>Free/Development tier: First 1,000 invokes included; Production tier: $50/month; Growth tier: $500/month; Enterprise tier: Custom</td>
    </tr>
    <tr>
      <td><a href="#ximilar">Ximilar</a></td>
      <td>Image classification, image tagging, object detection, image regression, semantic image search</td>
      <td>🟨 <strong>30 mins minimum.</strong> Join via Google account; 5 mins to navigate to the right model option; 20+ mins to train model; seconds to deploy on new data.</td>
      <td>✅ 7/7 correct</td>
      <td>“Visual AI for Business.” Industries listed on site: collectible items, biotech &amp; medtech, e-commerce, fashion, manufacturing, real estate, safety &amp; security, stock photography.</td>
      <td>Free tier: 3,000 API credits/month; Business tier: $59-$285/month; Professional tier: $499-$3,125/month Optional extra credit packs and custom plans.</td>
    </tr>
    <tr>
      <td><a href="#roboflow">Roboflow</a></td>
      <td>Image classification, image tagging, object detection, instance segmentation, semantic segmentation</td>
      <td>🟨 <strong>30 mins to 24 hours.</strong> Join via Google account; 20 mins from sign up to beginning to train model; model trained in 6 mins (can be up to 24 hours); new images trained one at a time.</td>
      <td>🟨 6/7 correct</td>
      <td>“Deploy a computer vision model in an afternoon.” Many industries are listed on their site, including healthcare &amp; medicine, manufacturing, agriculture, aerospace &amp; defense, automotive, banking &amp; finance, transportation, and more.</td>
      <td>Free/public tier: first 1,000/month inference credits included; Growth tier: Free trial, then individual pricing based on usage; Enterprise tier: Custom</td>
    </tr>
    <tr>
      <td><a href="#hasty">Hasty</a></td>
      <td>Image tagging, instance segmentation, object detection, semantic segmentation</td>
      <td>❌ <strong>At least 30 mins; can be considerably more.</strong> Join via Google account; a few minutes to upload images (after quite a bit of looking around for where to do it), and then several more minutes to manually label them (difficult to figure out).</td>
      <td>❌ 2/7 correct</td>
      <td>“Data-centric ML platform” specializing in CV for ML engineers and domain experts.</td>
      <td>Free tier; Self service tier: €300-€4,000/month; Enterprise tier: Custom</td>
    </tr>
    <tr>
      <td><a href="#levity">Levity</a></td>
      <td>Image classification, image tagging</td>
      <td>🟨 <strong>5–10 mins.</strong> UI is very intuitive and clean. Labeling training data took a few mins. Model training took about 4 more minutes.</td>
      <td>🟨 5/7 correct. Adding correct images to training data did not help with final 2.</td>
      <td>“Powerful AI for daily tasks.” Mid-market companies and SMEs.</td>
      <td>Free trial; Startup tier: $49-$119/month; Business tier: $139-$1,849/month; Enterprise tier: Custom</td>
    </tr>
    <tr>
      <td><a href="#clarifai">Clarifai</a></td>
      <td>Image classification, image tagging, object detection, semantic image search semantic segmentation, instance segmentation</td>
      <td>🟨 <strong>30 minutes.</strong> Join via a Google account; create an “application;” manually label images; train model.</td>
      <td>🟨 5/7 correctly classified. 6/7 correctly classified after including the 5 it initially correctly classified in the model.</td>
      <td>“The World’s AI™” for developers, data scientists, and no-code operators.</td>
      <td>Free/community tier: 1,000 operations/month; Essential tier: Starts at $30/month; Professional tier: Starts at $300/month; Enterprise tier: Custom</td>
    </tr>
    <tr>
      <td><a href="#google-vertex-ai">Google Vertex AI</a></td>
      <td>Image classification, image tagging, object detection</td>
      <td>❌ <strong>1-3 hours.</strong> Create an account via Google Cloud; enter credit card details; sift through Google apps to find the right one; navigate several frustrating steps &amp; errors; use YouTube find to complete our task.</td>
      <td>🟨 6/7</td>
      <td>“Fully managed ML tools for any use case.” For developers and enterprises.</td>
      <td>Pricing varies based on the input type of the data (image, video), the ML operation you’re completing, and whether you’re doing image classification or object detection. <strong><a href="https://cloud.google.com/vertex-ai/pricing#image-data">See pricing chart.</a></strong></td>
    </tr>
    <tr>
      <td><a href="#azure-custom-vision">Azure Custom Vision</a></td>
      <td>Image classification, image tagging, object detection</td>
      <td>❌ <strong>1-2 hours.</strong> Create a Microsoft account; be redirected to sign in multiple times; navigate error messages &amp; confusing steps; find YouTube video for support; quick training &amp; testing of the model after frustrating set up.</td>
      <td>✅ 7/7</td>
      <td>“State-of-the-art computer vision models for your unique use case.” For developers and enterprises.</td>
      <td>Free tier: 2 transactions per second (TPS), 5,000 training images per project, and 10,000 predictions/month. Standard tier: 10 TPS, $2 per 1,000 transactions, $10 per compute hour, $0.70 per 1,000 images.</td>
    </tr>
    <tr>
      <td><a href="#aws-rekognition-custom-labels">AWS Rekognition Custom Labels</a></td>
      <td>Image classification, image tagging, object detection</td>
      <td>❌ <strong>2-3 hours.</strong> Complete tedious set up process; watch video tutorial; complete next steps; discover that coding is required to deploy; abandon test.</td>
      <td>❌ <strong>N/A</strong> - requires users to download software and code to deploy/test the model, so we did not test performance.</td>
      <td>“Automate and lower the cost of your image recognition and video analysis.” For developers and enterprises.</td>
      <td>Free tier: lasts 3 months and includes 10 free training hours/month and 4 free interference hours/month. After free tier: Training is $1/hour and interference is $4/hour.</td>
    </tr>
  </tbody>
</table></div>

<h2 id="comparison-takeaways-computer-vision-saas-players">Comparison takeaways: Computer vision SaaS players</h2>

<p>We learned a lot through this benchmarking task, but there are a few broad-stroke insights to take away from it:</p>

<ul>
  <li><strong>Accuracy varied:</strong> Not all of the computer vision service providers correctly classified our test images. This doesn’t speak to their capabilities in general, but it is clearly relevant to the user experience when things don’t behave as desired right out of the box.</li>
  <li><strong>On-the-fly training was possible with a small subset:</strong> Most of the APIs had an explicit training cycle, although some models (Nyckel and Ximilar) updated on the fly as images were labeled. This is a relevant differentiator if you’re trying to test a model quickly or want immediate feedback as you annotate your training data.</li>
  <li><strong>Intuitiveness varied:</strong> Some APIs had very intuitive and clean UIs, whereas others offered a high-level of customization and an equally high-level of documentation to wade through.</li>
  <li><strong>Pricing is difficult to compare across providers:</strong> All services had a no-fee option, sufficient for training and deploying at least for a few models based on small datasets, as well as various paid subscriptions. Some pricing structures were more straightforward than others, with Vertex AI’s being the most confusing. It’s difficult to directly compare the providers on cost because some of them quote flat fees, while others price their services according to the number of models deployed, data points predicted, or computational resource-hours used for different activities. The larger providers add in more intensive customer service as an extra for their higher tiers, whereas this tends to be included or left unspecified by the smaller providers. To get a precise determination of cost, a customer will still have to ring around for quotes from their potential providers.</li>
  <li><strong>Not all were actually full-stack:</strong> We set out to only include full-stack computer vision providers in this benchmark. But after experimenting with the platforms, we discovered two of the platforms, Clarifai and AWS Rekognition, required us to download software and do some coding to deploy the model. We looked for an alternative way to test the platforms’ ability to label our subset of test data. Clarifai’s customer service pointed us to a “context-based classifier,” which we used, but we had to abandon the test at this stage for AWS.</li>
</ul>

<p>Now we’ll dive a little deeper into each of the players we evaluated.</p>

<p><em>(Reminder: we hired an independent freelance writer to assess the functionality and performance of all of the platforms, including Nyckel.)</em></p>

<h3 id="nyckel">Nyckel</h3>

<figure class="figure">

    

    

    

    
    <a href="https://www.nyckel.com">
        
        <div class="post-img">
        <!-- Add the 'boxed' class if 'box' attribute is 'yes' -->
        <img src="../images/nyckel-cv-saas2.webp" alt="Nyckel computer vision SaaS" class=" " style="border-radius: 20px; max-width: 100%" srcset="../images/nyckel-cv-saas2.webp 2x%" loading="lazy" />
    </div>
    <figcaption></figcaption>
        
    </a>
    

</figure>

<p><strong><em>Super quick and accurate with a breadth of ML services</em></strong></p>

<p><a href="https://www.nyckel.com/">Nyckel</a> offers a fast and intuitive machine learning API for developers and product teams without in-house ML expertise. Unlike some of the other small players here, Nyckel’s function types extend beyond computer vision to also include text and tabular classification, tagging, and search. Nyckel’s computer vision product demonstrated impressive performance through its ease of use, fast setup, and accurate predictions. Its drag-and-drop data upload and bulk labeling allowed us to import and label the images in just seconds or minutes for each batched category.</p>

<p>The model trained on the fly, and its predictions continued to update during data upload and annotation without further prompting. The model will continue to update on-the-fly as new data is annotated and fed to the model. <strong>Nyckel was one of the three players that classified all 7/7 test images correctly (with high confidence), and it had the quickest time to the first model of all the players.</strong> Since Nyckel is newer to the market than the behemoths, it does not have a robust user community like Google, Amazon, or Microsoft.</p>

<h3 id="ximilar">Ximilar</h3>

<figure class="figure">

    

    

    

    
    <a href="https://www.ximilar.com">
        
        <div class="post-img">
        <!-- Add the 'boxed' class if 'box' attribute is 'yes' -->
        <img src="../images/ximilar-cv-saas.webp" alt="Ximilar computer vision SaaS" class=" " style="border-radius: 20px; max-width: 100%" srcset="../images/ximilar-cv-saas.webp 2x%" loading="lazy" />
    </div>
    <figcaption></figcaption>
        
    </a>
    

</figure>

<p><strong><em>User-friendly and accurate with a narrow focus on computer vision</em></strong></p>

<p><a href="https://www.ximilar.com/">Ximilar</a> specializes in computer vision, with various pre-trained models available for particular use cases (e.g., retail image classifiers or automotive industry classifiers). We avoided these ready-made options, instead training a new model “from scratch” (still with the benefit of the service’s use of transfer learning). Overall, Ximilar’s product was very user-friendly, despite a few connection glitches we experienced. Like Nyckel, it had a simple and fast drag-and-drop interface for data import and bulk labeling.</p>

<p>After uploading the data, model training took about 20 minutes, which was good/average for these platforms. <strong>Ximilar was one of the three players that classified all 7/7 test images correctly.</strong> Like Nyckel and the other small players, it cannot compete with the behemoths regarding their large user communities. An interesting feature of Ximilar’s was an “Explain” feature which overlays a heat map onto the image to indicate how the AI assigned weightings to different image pixels.</p>

<h3 id="roboflow">Roboflow</h3>

<figure class="figure">

    

    

    

    
    <a href="https://www.roboflow.com">
        
        <div class="post-img">
        <!-- Add the 'boxed' class if 'box' attribute is 'yes' -->
        <img src="../images/roboflow-cv-saas.webp" alt="Roboflow computer vision SaaS" class=" " style="border-radius: 20px; max-width: 100%" srcset="../images/roboflow-cv-saas.webp 2x%" loading="lazy" />
    </div>
    <figcaption></figcaption>
        
    </a>
    

</figure>

<p><strong><em>Computer vision platform for enthusiasts who want to get into the details</em></strong></p>

<p>Like Ximilar, <a href="https://roboflow.com">Roboflow</a> specializes in computer vision. Roboflow’s computer vision product features a drag-and-drop interface for uploading images and videos, and it supports bulk labeling. It offered two training options: “Fast” and “Accurate,” with the latter only available for paid plans.</p>

<p>Roboflow gave us the choice of whether to train our model based on a previous run of the model (not applicable here), with reference to a public checkpoint (recommended by Roboflow), or to train from scratch. We picked the recommended public checkpoint option. We also had the option to preprocess and augment our images for training. We initially left the default options in place (auto-orient and stretch resizing), but our first model was struggling to correctly classify the images, so we generated a new model without the preprocessing options. That new model performed better; <strong>Roboflow classified 6/7 test images correctly, and training the model took only six minutes.</strong></p>

<p>Although Roboflow offers a range of options for model tweaking, a subscription is required to explore these custom options and apply them to new models. While small in comparison to the large enterprise players, Roboflow has a fairly robust library of resources.</p>

<h3 id="hasty">Hasty</h3>

<figure class="figure">

    

    

    

    
    <a href="https://hasty.cloudfactory.com/">
        
        <div class="post-img">
        <!-- Add the 'boxed' class if 'box' attribute is 'yes' -->
        <img src="../images/hasty-cv-saas.webp" alt="Hasty computer vision SaaS" class=" " style="border-radius: 20px; max-width: 100%" srcset="../images/hasty-cv-saas.webp 2x%" loading="lazy" />
    </div>
    <figcaption></figcaption>
        
    </a>
    

</figure>

<p><strong><em>Low performance &amp; usability — but may perform better with image classification (if the option exists)</em></strong></p>

<p><a href="https://hasty.cloudfactory.com">Hasty</a> also specializes in computer vision and calls itself a “data-centric ML platform.” Even though Hasty markets image classification on its website, we couldn’t find an option within the product (at least without paying) to use image classification. Because of this, we used object detection applied to the entire image as a workaround. While, in theory, this method should yield the same outcome as classifying an image as containing a certain object, object detection is usually more computationally intensive than image classification. This means that while there may not be a noticeable difference in speed with smaller datasets, object detection could potentially be slower when dealing with larger ones.</p>

<p>The process of annotating our training data using Hasty’s object detection function was tedious; it required us to click four times around each image to <a href="https://www.nyckel.com/blog/are-bounding-boxes-necessary-for-object-detection/">create a bounding box</a> and then individually label each image. This process proved time-consuming, taking over 25 minutes — which is much longer than the services that allowed bulk labeling. After annotating 28 of our images, the model started training and displayed an accuracy bar for us to track as we annotated more data. After annotating 36 images, Hasty started to (inaccurately) label our training data, so we continued to annotate the remaining 41 images ourselves.</p>

<p><strong>When it came time to test Hasty’s model accuracy, Hasty had the weakest performance out of all the evaluated products, correctly classifying only 2 out of 7 images.</strong></p>

<h3 id="levity">Levity</h3>

<figure class="figure">

    

    

    

    
    <a href="https://levity.ai/">
        
        <div class="post-img">
        <!-- Add the 'boxed' class if 'box' attribute is 'yes' -->
        <img src="../images/levity-cv-saas.webp" alt="Levity computer vision SaaS" class=" " style="border-radius: 20px; max-width: 100%" srcset="../images/levity-cv-saas.webp 2x%" loading="lazy" />
    </div>
    <figcaption></figcaption>
        
    </a>
    

</figure>

<p><strong><em>Easy-to-use with many no-code integrations, core ML performance lagging others</em></strong></p>

<p><a href="https://levity.ai/">Levity</a> specializes in automating everyday, mundane tasks, including tagging and classifying product images, managing inventory, categorizing email responses, and more. When it comes to computer vision tasks, Levity has less breadth than the other players in this article. The user experience of annotating the training data was a bit different with Levity than the other products; after we uploaded images, Levity displayed them in a one-page tile format, with a drop-down labeling button overlaid on each image. We couldn’t figure out how to bulk label the image set, but the labeling functionality and tile layout made it quick and easy.</p>

<p>Model training only took a few minutes to complete, and <strong>Levity correctly classified 5/7 of our test images — landing in the middle of the pack for performance.</strong> Adding the test images into the training set did not improve the performance of the model.</p>

<h3 id="clarifai">Clarifai</h3>

<figure class="figure">

    

    

    

    
    <a href="https://www.clarifai.com">
        
        <div class="post-img">
        <!-- Add the 'boxed' class if 'box' attribute is 'yes' -->
        <img src="../images/clarifai-cv-saas.webp" alt="Clarifai computer vision SaaS" class=" " style="border-radius: 20px; max-width: 100%" srcset="../images/clarifai-cv-saas.webp 2x%" loading="lazy" />
    </div>
    <figcaption></figcaption>
        
    </a>
    

</figure>

<p><strong><em>The OG offers a comprehensive product suite in a somewhat confusing platform</em></strong></p>

<p><a href="https://www.clarifai.com">Clarifai</a> is a broad ML service provider, calling itself the “easiest deep learning AI platform for developers, data scientists, and no-code operators.” (Spoiler: We don’t agree.) Clarifai’s computer vision product offered an interesting mix of ease-of-use and complexity. The data upload process was straightforward, offering drag-and-drop functionality or the option to browse files. However, when attempting to label a batch of images in one go using the drag-and-drop method, we encountered an “invalid request” error message, so we annotated the images one-by-one. Despite this hiccup, the user interface was relatively streamlined and intuitive.</p>

<p>However, we found some of Clarifai’s terminology confusing. For example, Clarifai calls image labels “concepts,” and you have to sort through all sorts of classifier options to find the one that’s best for you. At times, the product’s functionality was confusing too; we weren’t sure what to do first after we created our account and before we asked Clarifai to train the model, we had to set a bunch of parameters, but we weren’t sure what the parameters meant, so we mostly just kept the default settings.</p>

<p>Once we had uploaded and annotated our image data, we attempted to train the model. But we were prompted to sign up for a paid plan. Upon reaching out to Clarifai about this issue, they suggested using the free context-based classifier instead of the initially-selected visual classifier. We then retrained our model using the context-based classifier. <strong>Clarifai correctly classified 5 out of 7 images, albeit with some notably low confidence scores.</strong> When we added the test data into the training data, we were able to enhance the performance to correctly classify 6 out of 7 images.</p>

<p>Clarifai was the only smaller provider that talked about its user community and had a dedicated Slack channel for users, suggesting a commitment to user engagement and support.</p>

<h3 id="google-vertex-ai">Google Vertex AI</h3>

<figure class="figure">

    

    

    

    
    <a href="https://cloud.google.com/vertex-ai">
        
        <div class="post-img">
        <!-- Add the 'boxed' class if 'box' attribute is 'yes' -->
        <img src="../images/vertex-ai-cv-saas.webp" alt="Google Vertex AI computer vision SaaS" class=" " style="border-radius: 20px; max-width: 100%" srcset="../images/vertex-ai-cv-saas.webp 2x%" loading="lazy" />
    </div>
    <figcaption></figcaption>
        
    </a>
    

</figure>

<p><strong><em>Steep learning curve with solid accuracy and helpful user tutorials</em></strong></p>

<p><a href="https://cloud.google.com/vertex-ai">Vertex AI</a> is Google’s “unified data and AI platform” for machine learning developers, data scientists, and data engineers. Google’s large cloud ecosystem meant we needed to first create a Google Cloud account and then sift through the many APIs and ML apps Google offers before landing on Vertex AI.</p>

<p>The model training and testing process wasn’t all that simple or quick either. For example, after importing our training data images, we were asked to select “Default,” “Training,” “Validation,” or “Test” for every single image from a drop down menu. We left the images set as default instead of clicking 80 times. Once it came time to label our test data, we resorted to manually labeling each image because Vertex AI’s alternative option (upload a PDF to a Google Cloud Console folder and then select that file within Vertex AI) wasn’t working.</p>

<p>Once we (finally) got to the model training step, Google asked us to choose between a high accuracy (but slower) model or a lower accuracy (but faster) model. Since our dataset is small and a lower latency isn’t a concern, we chose high accuracy. After this step, things got confusing. Our model had completed its training and we were ready to add our test images, but we had to stumble through Google documentation and YouTube tutorials to figure out next steps, before we finally found our way to where we could upload our test images one image at a time.</p>

<p><strong>Vertex AI correctly classified 6 out of 7 of the test images.</strong> While cumbersome, complex, and slow at times, the sheer size of the Google ecosystem means you can find many explainer videos online to help you along in the Vertex AI process.</p>

<h3 id="azure-custom-vision">Azure Custom Vision</h3>

<figure class="figure">

    

    

    

    
    <a href="https://azure.microsoft.com/en-us/products/cognitive-services/custom-vision-service">
        
        <div class="post-img">
        <!-- Add the 'boxed' class if 'box' attribute is 'yes' -->
        <img src="../images/azure-cv-saas.webp" alt="Azure Custom Vision" class=" " style="border-radius: 20px; max-width: 100%" srcset="../images/azure-cv-saas.webp 2x%" loading="lazy" />
    </div>
    <figcaption></figcaption>
        
    </a>
    

</figure>

<p><strong><em>Getting started is an absolute headache, but the model performs accurately</em></strong></p>

<p><a href="https://azure.microsoft.com/en-us/products/cognitive-services/custom-vision-service">Azure Custom Vision</a> is the computer vision component of Azure Cognitive Services, which is Microsoft’s AI services that “help developers build cognitive intelligence into applications without having direct AI or data science knowledge.” Setting up our Custom Vision account was nothing short of frustratingly annoying; it required about eight steps and several redirects back to the sign-in page just to get into the Custom Vision app. Then, after a confusing set of next steps, we turned to YouTube for help. Fortunately, we found a video that simplified the process by directing us to a more straightforward dashboard than what we had initially found.</p>

<p>When it was finally time to set up our model, Azure asked us to choose a domain for our task, which included (among other options) three different “general” domains. Upon inspecting these further, we chose General [A1], which was recommended for larger datasets or more difficult user scenarios (since one image, in particular, kept tripping up the other players, we opted for this option). Uploading our training data images was simple, and we were able to bulk-label each subset of images. When given the choice of Quick or Advanced training, we chose Quick. The model was ready four minutes later.</p>

<p><strong>Azure Custom Vision was one of the three players that classified all 7/7 test images correctly.</strong> However, logging in and getting started was the worst experience of any of the players we evaluated. Once we finally got set up in Custom Vision, training and testing the model was as quick as any of the simpler APIs. Like the other large players, Custom Vision has a lot of online resources to turn to when you get confused (fortunately for us).</p>

<h3 id="aws-rekognition-custom-labels">AWS Rekognition Custom Labels</h3>

<figure class="figure">

    

    

    

    
    <a href="https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/what-is.html">
        
        <div class="post-img">
        <!-- Add the 'boxed' class if 'box' attribute is 'yes' -->
        <img src="../images/aws-cv-saas.webp" alt="AWS Custom Vision" class=" " style="border-radius: 20px; max-width: 100%" srcset="../images/aws-cv-saas.webp 2x%" loading="lazy" />
    </div>
    <figcaption></figcaption>
        
    </a>
    

</figure>

<p><strong><em>Tedious set-up; deployment required coding, so we couldn’t test its performance</em></strong></p>

<p><a href="https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/what-is.html?pg=ln&amp;sec=ft">Amazon Rekognition Custom Labels</a> is one component of Amazon Rekognition, which includes a variety of pre-trained and customizable computer vision APIs. Amazon says customers can use Custom Labels to “identify the objects, logos, and scenes in images that are specific to your business needs.” Like Azure Custom Vision, Amazon Rekognition’s sign up process is tedious; it took us 10 minutes to just get into the product.</p>

<p>Once in the product’s interface, we followed a video tutorial to get through the first steps until we got to a dashboard that was self-explanatory and laid out the steps to completion nicely. Uploading images was pretty easy (you can only upload 30 at a time, so we did it in 3 batches), but we had to assign a label to each image individually. Unfortunately, once it was time to use/test our model, it required coding with Python. <strong>Coding with Python was beyond the scope of this benchmark, so we had to abandon our test with Custom Labels at this point.</strong></p>

<h2 id="so-whats-the-right-way-to-choose-a-cv-service-provider">So what’s the right way to choose a CV service provider?</h2>

<p>The <a href="https://www.nyckel.com/blog/guide-to-computer-vision-for-non-ml-experts/">computer vision market</a> is large and diverse. Even restricting our search to providers that offer self-service, full-stack services that require no ML skills still leaves room for a lot of differentiation, and therefore, a lot to think about when choosing a provider.</p>

<p>The comparison criteria used here (functionality, time to first model, performance, market positioning and pricing) can make the difference between similar options – provided that you have an accurate characterization of the relative importance of your UX and business needs.</p>

<p>This means figuring out what you need from a computer vision SaaS provider. Here are some questions to consider:</p>

<ul>
  <li>Does the platform support the function type(s) that your business needs? (E.g., image classification, object detection, or image tagging.) Does the platform offer broad enough function types that can support future use cases?</li>
  <li>How important is ease of use and the ability to train new users quickly? Is the platform intuitive, or does it require a deep dive into technical documentation?</li>
  <li>How accurate is the platform when you run it through some test data sets? Is the platform’s performance good enough for production deployment?</li>
  <li>Is pricing transparent and within your budget? Does it still fit your budget as you increase the number of model invokes?</li>
</ul>

<p>If you’re interested in exploring Nyckel in more depth, <a href="https://www.nyckel.com/console">sign up for a free account</a> or click through any of our quick starts, including <a href="https://www.nyckel.com/docs/image-classification-quickstart">image classification</a> or <a href="https://www.nyckel.com/docs/detection-quickstart">object detection</a>.</p>


  </div>

</article></div></div></div>
</div><!--</div>-->

<!-- Above-the-fold JS tags -->
<script src="/assets/js/jquery.min.js"></script>
<script src="/assets/js/popper.min.js"></script>
<script src="/assets/js/bootstrap.min.js"></script>
<script src="/assets/revolution/js/jquery.themepunch.tools.min.js"></script>
<script src="/assets/revolution/js/jquery.themepunch.revolution.min.js"></script>
<script src="/assets/js/plugins.js"></script>
<script src="/assets/js/scripts.js"></script>
<script src="/assets/js/codebox.js" defer></script>

<!-- Scroll-Delayed Tags -->
<script>
    var jsUrls = [
        "/assets/revolution/js/extensions/revolution.extension.actions.min.js",
        "/assets/revolution/js/extensions/revolution.extension.carousel.min.js",
        "/assets/revolution/js/extensions/revolution.extension.kenburn.min.js",
        "/assets/revolution/js/extensions/revolution.extension.layeranimation.min.js",
        "/assets/revolution/js/extensions/revolution.extension.migration.min.js",
        "/assets/revolution/js/extensions/revolution.extension.navigation.min.js",
        "/assets/revolution/js/extensions/revolution.extension.parallax.min.js",
        "/assets/revolution/js/extensions/revolution.extension.slideanims.min.js",
        "/assets/revolution/js/extensions/revolution.extension.video.min.js",
        "/assets/js/simple-jekyll-search.min.js",
    ];

    var hasLoadedJsFiles = new Array(jsUrls.length).fill(false);

    window.onscroll = function() {
        for (var i = 0; i < jsUrls.length; i++) {
            if (!hasLoadedJsFiles[i]) {
                var script = document.createElement('script');
                script.src = jsUrls[i];
                script.type = 'text/javascript';
                document.body.appendChild(script);

                // Remember that we've loaded this JavaScript file so we don't try to load it again
                hasLoadedJsFiles[i] = true;
            }
        }
    };
</script>


 <div><div class="wrapper image-wrapper light-wrapper bg-auto no-overlay bg-image text-center" data-image-src="/assets/images/important/map.webp">
                <div class="container inner">
                    <div class="row">
                        <div class="col-md-9 mx-auto">
                             <h3 class="display-3">Subscribe for more ML content</h3>

     <p class="lead" style="padding-left:15%;padding-right:15%">
                            You'll get periodic newsletters around machine learning, classification, and how anyone can build their own AI/ML models in just minutes.</p>
 <div class="space20"></div>
<ul class="navbar-nav flex-row align-items-center justify-content-center" data-sm-skip="true" style="justify-content: center; width: 100%;">
    <li class="nav-item">
      <div class="navbar-hamburger d-lg-none d-xl-none ml-auto">
        <button data-tf-popup="WRFhNxwm" data-tf-iframe-props="title=Newsletter Signup" data-tf-medium="snippet"
        data-tf-size="70"></button>
      </div>
    </li>
    <li class="nav-item d-none d-lg-block pl-0" style="padding-right:2%">
      <a href="/contact/" class="btn m-0" style="background-color:#e7a83d;">Sign-up</a>
    </li>
    
    
</ul>
                  
                  
                        </div>
                    </div>
                </div>
            </div>

  <script src="//embed.typeform.com/next/embed.js"></script></div></div></div></div></div> -->
<footer class="image-wrapper bg-image page-title-wrapper inverse-text" data-image-src="/assets/images/important/home-bg.webp" loading="lazy"> 

  <div class="container inner pt-80 pb-50 text-center">
    <div class="row">
      <div class="col-md-10 offset-md-1">
        <div class="row">


           <div class="col-md-3">
            
        <div class="widget">
          
           <div class="h5 widget-title" style="color: white;">Learn More</div>
          
          <ul class="list-unstyled mb-0">
            
            <li><a href="/pricing/">Pricing</a></li>
            
            <li><a href="/public-functions/">Pre-Trained Models</a></li>
            
            <li><a href="/customers/">Customers</a></li>
            
          </ul>
        </div>
        <!-- /.widget -->
          </div>
<div class="col-md-3">
            
        <div class="widget">
          
           <div class="h5 widget-title" style="color: white;">Get Started</div>
          
          <ul class="list-unstyled mb-0">
            
            <li><a href="/contact/">Contact</a></li>
            
            <li><a href="https://www.nyckel.com/console">Sign-Up</a></li>
            
          </ul>
        </div>
        <!-- /.widget -->
          </div>
          <!-- /column -->

          <!-- /column -->

          <div class="col-md-3">
            
        <div class="widget">
          
           <div class="h5 widget-title" style="color: white;">Developers</div>
          
          <ul class="list-unstyled mb-0">
            
            <li><a href="https://www.nyckel.com/docs">API Docs</a></li>
            
            <li><a href="https://status.nyckel.com/">API Status</a></li>
            
          </ul>
        </div>
        <!-- /.widget -->
          </div>


          <div class="col-md-3">
            
        <div class="widget">
          
           <div class="h5 widget-title" style="color: white;">Company</div>
          
          <ul class="list-unstyled mb-0">
            
            <li><a href="/about/">About</a></li>
            
            <li><a href="/blog/">Blog</a></li>
            
            <li><a href="mailto:feedback@nyckel.com">Support</a></li>
            
          </ul>
        </div>
        <!-- /.widget -->
          </div>
          <!-- /column -->
        </div>
        <!-- /.row -->
      </div>
      <!-- /column -->
    </div>
    <div class="space30"></div>
    <p class="text-center">© 2023 Nyckel | <a href="/privacy-policy/">Privacy Policy</a> | <a href="/terms-and-conditions/">T&Cs</a></p>
      <ul class="social social-mute social-s">
                
               <li><a href="https://github.com/nyckelai" title="Nyckel on Github"><i class="jam jam-github"></i></a></li>
                
               <li><a href="https://www.youtube.com/@nyckelai" title="Nyckel on YouTube"><i class="jam jam-youtube"></i></a></li>
                
               <li><a href="https://www.linkedin.com/company/nyckelai/" title="Nyckel on LinkedIn"><i class="jam jam-linkedin"></i></a></li>
                
              </ul>
  </div>
</footer>


</body>

</html>