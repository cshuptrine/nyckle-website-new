I"w$<p>Image recognition is a term often used to describe using machine learning or computer vision to recognize and identify what‚Äôs in an image. Even though people use the term image recognition frequently, its meaning is vague, which can cause confusion and misunderstanding. For example, when someone says image recognition, they likely actually mean one of the following <a href="https://www.nyckel.com/blog/glossary-of-computer-vision-function-types/">types of computer vision</a>:</p>

<ul>
  <li><strong>Image classification:</strong> Assigns a <em>single</em> label to an entire image. For example, you can train an image classification function to <a href="https://www.nyckel.com/blog/ai-image-detector-can-you-use-image-classification-to-spot-the-fakes/">determine whether an image is AI-generated or not</a>.¬†</li>
  <li><strong>Image tagging:</strong> Assigns <em>multiple</em> tags (i.e., labels) to an image. For example, you can train an image tagging model to identify all the colors in an article of clothing.</li>
  <li><strong>Object detection:</strong> Locates and identifies instances of specific objects in images or videos. For example, you can train an object detector to <a href="https://www.nyckel.com/blog/are-bounding-boxes-necessary-for-object-detection/">identify how many instances of weeds are in a plot of grass</a>.</li>
</ul>

<p>Technically speaking, these computer vision function types use either <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks</a> (CNNs) or <a href="https://medium.com/data-and-beyond/vision-transformers-vit-a-very-basic-introduction-6cd29a7e56f3#:~:text=What%20is%20a%20Vision%20Transformer,and%20other%20computer%20vision%20tasks.">vision transformers</a> (ViT) to identify patterns in the pixels or patches of an image. CNNs was widely accepted as the standard model architecture for image classification, but recent advancements have vision transformers emerging as superior.</p>

<h2 id="what-do-you-really-mean-by-image-recognition">What do you really mean by image recognition?</h2>

<p>If you‚Äôve set out to solve an image recognition problem, your first task is to determine which computer vision function type you really mean. To do this, it‚Äôs helpful to think about what you‚Äôre doing as a ‚Äúblack box‚Äù function where your input is an image. Then, think about what you want your output to be. For example:</p>

<ul>
  <li>
    <p><strong>Do you want to label the image with one label out of two or more possible choices?</strong> If so, you need to create an image classification function (also called multi-class classification).</p>

    <p>For example, if you‚Äôre a car dealership that wants to use AI to label its vehicle inventory with the brand name of each car, you could create an image classification function. The input image would be the photo of the vehicle and the output labels would be all of the brands that you stock in your dealership. For example: Ford, Honda, Toyota, Kia, Hyundai.</p>
  </li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/image-recognition-honda-cars.png" alt="Image classification to identify car make" style="border-radius: 20px; max-width: 80%" srcset="../images/image-recognition-honda-cars.png 2x%" />
        <figcaption></figcaption>
        

</figure>

<ul>
  <li>
    <p><strong>Do you want to label the image with multiple labels or tags?</strong> If so, you need to create an image tagging function (also called <a href="https://www.nyckel.com/blog/multi-class-classification-vs-multi-label-classification-key-differences-how-to-choose/">multi-label classification</a>).¬†</p>

    <p>For example, if you‚Äôre an online retailer that wants to speed the process of tagging product inventory with all of its colors, you could create an image tagging function. The input image would be the article of clothing, and the output labels would be all of the possible colors. For example: yellow, orange, red, pink, purple, blue, green, black, white, brown.</p>
  </li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/image-recognition-boy-blue.png" alt="Image tagging to automatically identify colors on clothing" style="border-radius: 20px; max-width: 80%" srcset="../images/image-recognition-boy-blue.png 2x%" />
        <figcaption></figcaption>
        

</figure>

<ul>
  <li>
    <p><strong>Do you want to pinpoint the exact location of one or more specific objects in an image?</strong> If so, you need to create an object detection function.</p>

    <p>For example, if you are a brand manager that wants to monitor how your product inventory is displayed on store shelves, you could use an object detector to identify all instances of your products, like Cheerios boxes.</p>
  </li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="https://www.nyckel.com/_content/Marketing/images/function-example-store@2x.jpg" alt="Object detection to identify products on store shelves" style="border-radius: 20px; max-width: 100%" srcset="https://www.nyckel.com/_content/Marketing/images/function-example-store@2x.jpg 2x%" />
        <figcaption>Nyckel object detector identifies Maple Cheerios on a store shelf.</figcaption>
        

</figure>

<p>While any of these computer vision function types <em>could</em> be referred to as image recognition, it‚Äôs best to be more specific, so that you can identify the best approach for solving your challenge and which machine learning services are best designed to support you.</p>

<h2 id="which-image-recognition-service-is-best-for-you">Which image recognition service is best for you?</h2>

<p>Once you have a better idea of the type of image recognition you need, you can start to look for machine learning services that can help you solve your problem. One distinction to be aware of as you search for an ML service is whether pretrained models will work for your use case or if you‚Äôll need to build a custom model.</p>

<p><strong>Pretrained models</strong> have already been trained on a large dataset, so you can use these models out of the box to make predictions about your own dataset. In other words, you don‚Äôt need to come up with your own training data to train the model. The downside of pretrained models is that, since they haven‚Äôt been trained on your unique data, they may not perform as well as you‚Äôd like them to when you test them on your own data. Plus, you are constrained to using the output labels that the model was trained on, which may or may not work for your use case. One example of where this can be problematic is when you need to <a href="https://www.nyckel.com/blog/custom-auto-tagging-for-digital-asset-management/">label your digital assets with industry-specific terminology.</a></p>

<p>Popular services that offer pretrained models include <a href="https://cloud.google.com/vision?hl=en">Vision AI from Google</a>, <a href="https://portal.vision.cognitive.azure.com/gallery/featured">Vision Studio from Microsoft Azure</a>, and <a href="https://aws.amazon.com/rekognition/image-features/">Amazon Rekognition Image from AWS</a>. While Nyckel‚Äôs core product helps customers build custom ML models, we also have a <a href="https://www.nyckel.com/public-functions">library of pretrained models available</a>.</p>

<p><strong>Custom ML models</strong> allow you to train your model using your own training data and choose exactly what you‚Äôd like for your output labels. Contrary to popular belief, custom ML models do not usually need a ton of training data to perform exceptionally well. This is due largely in part to transfer learning, which allows you to fine-tune and adapt pretrained models when building a custom model. The best custom ML services also allow you to <a href="https://www.nyckel.com/blog/introducing-invoke-capture-integrated-active-learning/">easily retrain your model</a> as you learn where your model is underperforming.</p>

<p>Popular services that allow you to build custom models include <a href="https://www.nyckel.com/computer-vision-api">Nyckel</a> (üëã), <a href="https://www.ximilar.com/">Ximilar</a>, <a href="https://roboflow.com/">Roboflow</a>, <a href="https://levity.ai/">Levity</a>, <a href="https://www.clarifai.com/">Clarifai</a>, <a href="https://cloud.google.com/vertex-ai?hl=en">Google Vertex AI</a>, <a href="https://azure.microsoft.com/en-us/products/ai-services/ai-custom-vision">Azure Custom Vision</a>, and <a href="https://aws.amazon.com/rekognition/custom-labels-features/?nc=sn&amp;loc=3&amp;dn=4">AWS Rekognition Custom Labels</a>. (We did a <a href="https://www.nyckel.com/blog/computer-vision-saas-landscape-comparison-of-the-top-9-players/">comparison of all of these computer vision SaaS players</a> if you‚Äôre interested in seeing how they perform against each other.)</p>

<p>Interested in building a custom <a href="https://www.nyckel.com/docs/image-classification-quickstart">image classification</a>, <a href="https://www.nyckel.com/docs/image-tags-quickstart">image tagging</a>, or <a href="https://www.nyckel.com/docs/detection-quickstart">object detection</a> function? <a href="https://www.nyckel.com/console">Give Nyckel a try for free</a>, and reach out to us at any time for support with your use case.</p>
:ET