I"Û:<p>Computer vision refers to machine learning techniques used to understand and process image and video data. There are many types of computer vision with <a href="https://www.nyckel.com/blog/28-practical-computer-vision-use-cases/">numerous practical applications</a>. To give you a better understanding of <a href="https://www.nyckel.com/blog/guide-to-computer-vision-for-non-ml-experts/">computer vision</a>, we define some of the most common types.</p>

<ul>
  <li><strong>Object detection:</strong> <a href="https://www.nyckel.com/docs/detection-quickstart">Object detection</a> identifies the locations of certain objects in an image. Aside from finding the exact locations of objects, object detection is also frequently used to count the number of objects or to detect the presence or absence of an object. Typically, an object detector draws a rectangle, called a bounding box, around each targeted object that it finds.¬† A less common but faster approach is for the object detector to just detect the <a href="https://www.nyckel.com/blog/are-bounding-boxes-necessary-for-object-detection/">center points of each object</a>. For most applications, center detection can often give you all the information you need, allowing you to train and launch your model quicker than with bounding boxes.</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/02-object-detection-glossary-computer-functions.jpg" alt="Object detector identifies the presence of apples in an image" style="border-radius: 20px; max-width: 100%" srcset="../images/02-object-detection-glossary-computer-functions.jpg 2x%" />
        <figcaption>Nyckel‚Äôs object detector identifies apples in an image</figcaption>
        

</figure>

<ul>
  <li><strong>Image classification:</strong> Image classification categorizes images using predefined labels. One <a href="https://www.nyckel.com/blog/5-image-classification-examples-datasets-to-build-functions-with-nyckel/">image classification example</a> could be classifying images of street signs by labeling them with what type of sign they are: stop sign, yield sign, school zone, or pedestrian crossing. There are <a href="https://www.nyckel.com/blog/multi-class-classification-vs-multi-label-classification-key-differences-how-to-choose/">three types of image classification</a>: binary classification, multi-class classification, and multi-label classification. In binary classification, the image can be labeled with one of two labels. In multi-class classification, an image can be labeled with one label of many possible choices. And in multi-label classification, an image can be labeled with multiple labels of many possible choices.</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/03-image-classification-glossary-computer-vision-functions.jpg" alt="Image classifier classifies orange juice by their brand name" style="border-radius: 20px; max-width: 100%" srcset="../images/03-image-classification-glossary-computer-vision-functions.jpg 2x%" />
        <figcaption>Nyckel‚Äôs image classifier classifies orange juice by its brand</figcaption>
        

</figure>

<ul>
  <li><strong>Image tagging:</strong> Image tagging is another term that you can use to describe multi-label image classification. In image tagging, one image can be tagged with multiple labels. For example, if you have a photo of a dress that‚Äôs multiple colors, image tagging allows you to identify more than one color in the dress and tag it with all of the respective labels (e.g., green, red, and yellow).</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/04-image-tagging-glossary-computer-functions.jpg" alt="Image tagger identifies all of the categories that an image belongs to" style="border-radius: 20px; max-width: 100%" srcset="../images/04-image-tagging-glossary-computer-functions.jpg 2x%" />
        <figcaption>Nyckel‚Äôs image tagger identifies all of the food items on a plate</figcaption>
        

</figure>

<ul>
  <li><strong>Semantic image search:</strong> <a href="https://www.nyckel.com/blog/a-quick-guide-to-semantic-image-search-with-examples/">Semantic image search</a> lets you use either an image or text string to search for a certain object within a gallery of images. For example, you can search ‚Äúgreen dress‚Äù to find all of the green dresses within a database of images.</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/05-semantic-image-search-glossary-computer-vision-functions.jpg" alt="Semantic image search detects which images include black jeeps" style="border-radius: 20px; max-width: 100%" srcset="../images/05-semantic-image-search-glossary-computer-vision-functions.jpg 2x%" />
        <figcaption>Nyckel‚Äôs semantic image search identifies black jeeps in a photo library</figcaption>
        

</figure>

<ul>
  <li><strong>Semantic segmentation:</strong> Semantic segmentation breaks down the pixels of an image to determine what each pixel is. It identifies all of the pixels in an image and then tags them based on what category (i.e., object) they are. Semantic segmentation is particularly important for self-driving cars. Self-driving cars need to be able to accurately identify the drivable surface. Semantic segmentation functions look at each pixel of an image to determine: Is this pixel part of the road? A pedestrian? A street sign? Tagging what‚Äôs in front of and around the car with these labels tells the car where it can and can‚Äôt drive.</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/06-semantic-segmentation-glossary-computer-vision-functions.jpg" alt="TBD" style="border-radius: 20px; max-width: 100%" srcset="../images/06-semantic-segmentation-glossary-computer-vision-functions.jpg 2x%" />
        <figcaption>Semantic segmentation function identifies cats from dogs</figcaption>
        

</figure>

<ul>
  <li><strong>Instance segmentation:</strong> Instance segmentation is similar to object detection in that it identifies instances of objects within an image. Instead of drawing a box around the object or detecting its center, instance segmentation finds the precise pixels that correspond to that object. This additional precision comes at a cost. Training images need to be annotated in a similar manner, which is time-consuming. The training and inference process is also more computationally demanding and expensive as a result. But sometimes you need this additional precision. For example, when you want to remove a specific person from a photo while keeping the other people in it.</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/07-instance-segmentation-glossary-computer-vision-functions.jpg" alt="TBD" style="border-radius: 20px; max-width: 100%" srcset="../images/07-instance-segmentation-glossary-computer-vision-functions.jpg 2x%" />
        <figcaption>Instance segmentation function identifies instances of cats and dogs</figcaption>
        

</figure>

<ul>
  <li><strong>Text extraction or optical character recognition (OCR):</strong> Text extraction or OCR converts an image of text into text that‚Äôs machine-readable. For example, you can scan a hard copy of a form and convert it into an editable text document using text extraction.</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/08-text-extraction-glossary-computer-vision-functions.jpg" alt="Optical character recognition translates a coffee shop‚Äôs sign into text" style="border-radius: 20px; max-width: 100%" srcset="../images/08-text-extraction-glossary-computer-vision-functions.jpg 2x%" />
        <figcaption>Nyckel‚Äôs OCR function translates a coffee shop‚Äôs sign into text</figcaption>
        

</figure>

<ul>
  <li><strong>Scene reconstruction:</strong> Scene reconstruction enables the function to ‚Äúimagine‚Äù a visual that‚Äôs not actually in the image. For example, if someone in a photo is holding a balloon, the function can imagine what‚Äôs behind that balloon. Scene reconstruction can come in handy if you want to edit an object out of a photo but want to fill that blank space with what was behind it.</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/09-scene-reconstruction-glossary-computer-vision-functions.jpg" alt="AI research scientist uses machine learning to remove person and piece of garbage from image" style="border-radius: 20px; max-width: 100%" srcset="../images/09-scene-reconstruction-glossary-computer-vision-functions.jpg 2x%" />
        <figcaption>Photo credit: Louis Bouchard: &lt;https://pub.towardsai.net/this-ai-removes-unwanted-objects-from-your-images-29b2905df08e&gt;</figcaption>
        

</figure>

<ul>
  <li><strong>Event detection:</strong> Event detection detects certain events that happen in video data. For example, you might want to know if someone appeared on your home security camera. Using event detection, you can determine at what point in the video a person stepped in and out of the frame.</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/10-event-detection-glossary-computer-vision-functions.jpg" alt="Security cameras monitor for motion" style="border-radius: 20px; max-width: 100%" srcset="../images/10-event-detection-glossary-computer-vision-functions.jpg 2x%" />
        <figcaption></figcaption>
        

</figure>

<ul>
  <li><strong>Object tracking:</strong> Object tracking can show you where an object is at each moment in a video and can track the path of that object. For example, you can use video tracking to track the movements of a basketball through each frame of a recorded basketball game. This applies object detection (see earlier bullet) to videos.</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/11-object-tracking-glossary-computer-vision-functions.jpg" alt="Object tracker tracks the path of a basketball" style="border-radius: 20px; max-width: 100%" srcset="../images/11-object-tracking-glossary-computer-vision-functions.jpg 2x%" />
        <figcaption></figcaption>
        

</figure>

<ul>
  <li><strong>Motion estimation, aka optical flow:</strong> Building on object tracking, motion estimation enables you to predict where an object is going to be in the future. A fun example of this is creating <a href="https://www.youtube.com/watch?v=myO8fxhDRW0">a basketball hoop that won‚Äôt let you miss</a> because it predicts where the ball is going ‚Äî and where the hoop needs to be ‚Äî¬†for you to make the basket.</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/12-motion-estimation-glossary-computer-vision-functions.jpg" alt="Motion estimation predicts horse‚Äôs movement between video frames" style="border-radius: 20px; max-width: 100%" srcset="../images/12-motion-estimation-glossary-computer-vision-functions.jpg 2x%" />
        <figcaption>Motion estimation Wikipedia page: &lt;https://en.wikipedia.org/wiki/Motion_estimation&gt;</figcaption>
        

</figure>

<ul>
  <li><strong>Pose estimation:</strong> Pose estimation detects human figures and understands their body pose. It is used for things like gesture detection and motion capture.</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/13-pose-estimation-glossary-computer-vision-functions.jpg" alt=" Pose estimator detects the pose of people playing basketball" style="border-radius: 20px; max-width: 100%" srcset="../images/13-pose-estimation-glossary-computer-vision-functions.jpg 2x%" />
        <figcaption></figcaption>
        

</figure>

<ul>
  <li><strong>3D scene modeling:</strong> 3D scene modeling involves taking 2D photos of different walls within a room and asking the computer to reconstruct a 3D rendering. This is how companies like <a href="https://matterport.com/industries/real-estate">Matterport</a>, a spatial data company, create 3D virtual tours of homes using photos of the house.</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/14-3D-scene-modeling-glossary-computer-vision-functions.jpg" alt="3D scene modeler depicts an intersection in San Francisco" style="border-radius: 20px; max-width: 100%" srcset="../images/14-3D-scene-modeling-glossary-computer-vision-functions.jpg 2x%" />
        <figcaption>Photo credit: Simultaneous localization and mapping Wikipedia: &lt;https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping&gt;</figcaption>
        

</figure>

<ul>
  <li><strong>Image restoration:</strong> Image restoration removes noise, damage, and other distortions from an image and makes adjustments to the image based on predictions of what its original color, lighting, and other factors would have been.</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/15-image-restoration-glossary-computer-vision-functions.jpg" alt="Image restoration AI restores an old photo of a couple" style="border-radius: 20px; max-width: 100%" srcset="../images/15-image-restoration-glossary-computer-vision-functions.jpg 2x%" />
        <figcaption>Photo credit: Vance AI: &lt;https://vanceai.com/old-photo-restoration/&gt;</figcaption>
        

</figure>

<ul>
  <li><strong>Keypoint detection:</strong> Keypoint detection identifies and localizes different key object parts or ‚Äúkeypoints‚Äù within an object. For example, identifying noses, mouths, eyes and eyebrows as all being keypoints that constitute a human face. This is used for tasks such as face recognition and motion capture.</li>
</ul>

<figure class="figure">

    

    

    

    
        <img src="../images/16-keypoint-detection-glossary-computer-vision-functions.jpg" alt="Keypoint detector identifies points on a human face" style="border-radius: 20px; max-width: 100%" srcset="../images/16-keypoint-detection-glossary-computer-vision-functions.jpg 2x%" />
        <figcaption>Photo credit: Facial Keypoints Detector GitHub Project: &lt;https://github.com/3ba2ii/Facial-Keypoints-Detector&gt;</figcaption>
        

</figure>

<p>The science behind computer vision is complicated, but products like Nyckel make it accessible, even for companies that don‚Äôt have machine learning experts on staff. Take a look at our <a href="https://www.nyckel.com/docs/image-classification-quickstart">image classification</a>, <a href="https://www.nyckel.com/docs/detection-quickstart">object detection</a>, <a href="https://www.nyckel.com/docs/image-search-quickstart">image semantic search</a>, and <a href="https://www.nyckel.com/docs/ocr-quickstart">OCR quickstarts</a> to see how quick and easy it is to bring computer vision to your organization.</p>

<p>What other types of <a href="https://www.nyckel.com/blog/guide-to-computer-vision-for-non-ml-experts/">computer vision</a> would you like to see defined in this glossary?</p>

<p>Reach out to <a href="mailto:feedback@nyckel.com">feedback@nyckel.com</a>.</p>
:ET