I""8<p>At Nyckel, our goal is to not only make it simpler to solve problems with ML but also help developers and product teams learn what they actually need to know about ML to be successful in their roles. In this article, we’ll review one of the important ML distinctions you should know before building AI into your product: the differences between generative and discriminative AI.</p>

<table>
  <thead>
    <tr>
      <th><strong>Generative AI</strong></th>
      <th><strong>Discriminative AI</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Typically trained on very large language models (LLMs) to perform almost any task</td>
      <td>Can be trained on narrow models to perform very specific tasks (e.g., text or image classification), making it quick and easy to spin up functions</td>
    </tr>
    <tr>
      <td>Objective of the model is to create entirely new content using the data the model has been trained on</td>
      <td>Objective of the model is to make a decision based on data the model has been trained on</td>
    </tr>
    <tr>
      <td>Input and output are very flexible, often requiring prompt engineering to determine the best input to get the output needed</td>
      <td>Input is typically fixed schema (e.g., input: text string or image, output: predefined categories)</td>
    </tr>
    <tr>
      <td>Sometimes makes things up (hallucinates), which requires a human to confirm the output’s accuracy</td>
      <td>Having a human reviewer in the loop to moderate low confidence decisions and retrain the model with new annotated data can help improve model performance</td>
    </tr>
    <tr>
      <td>Solutions typically do not have the scaffolding required to discover problem cases and iterate on annotated data</td>
      <td>Best solutions enable a data engine — a process for detecting and managing problematic data</td>
    </tr>
    <tr>
      <td>Popular tools include ChatGPT, DALL-E, Jasper, Ask Codi, Sythesia, and Writesonic</td>
      <td>Popular tools include Nyckel, Roboflow, Vertex AI, Hugging Face, and Akkio</td>
    </tr>
  </tbody>
</table>

<h2 id="what-is-generative-ai">What is generative AI?</h2>

<p>We’ll start with the type of AI you’re likely most familiar with because it’s <a href="https://apnews.com/hub/generative-ai">driven much of the hype</a> in recent months: generative AI. The objective of generative AI is to create new content using what the ML model (a large language model) has learned from training data. The types of content you can create with generative AI are vast and include text, images, music, videos, 3D models, synthetic data, and more. One of the most commonly used forms of generative AI are customer support chatbots.</p>

<p>Generative AI solutions, like GPT-4, typically have flexible interfaces, meaning you can guide the models to respond in a way that aligns with what you’re trying to accomplish. The applications for generative AI almost feel limitless; if there’s a type of content you want to create and deliver to your customers via your product, you can probably do it with support from LLMs like GPT-4.</p>

<p>For all of the upside of generative AI, there are also challenges you’ll need to overcome: </p>

<ul>
  <li>Generative AI models are tricky to control. You never quite know what you’re going to get, so you may need a lot of trial and error (i.e., prompt engineering) to get closer to your desired output.</li>
  <li>These models are prone to making stuff up (i.e., hallucinating). You’ll need a human reviewer involved to confirm the accuracy of the model’s output.</li>
  <li>Most generative AI solutions lack the basic scaffolding required to help you solve discriminative (decision-based) tasks. More specifically, solutions like those from OpenAI don’t enable a <a href="https://www.nyckel.com/blog/9-ways-to-use-a-data-engine-to-improve-your-ml-model/">data engine</a> to help you discover corner cases and iterate on the labeling of your existing samples to ensure the model receives the right type of inputs.</li>
</ul>

<h3 id="generative-ai-skills">Generative AI skills</h3>

<p>The most important generative AI skills to know as a product manager or developer are <strong>prompt engineering</strong> and <strong>prompt chaining.</strong></p>

<p><strong>Prompt engineering</strong> is figuring out which words and phrases to use as an input to get the model to respond in the way you want it to (the output). Courses in prompt engineering are popping up left and right, and you can also learn a lot by searching for example prompts. But, in our opinion, the best way to learn is to jump into a tool like GPT-4 to give it a spin for yourself — experimenting with how different prompts get different results.</p>

<p>Here’s how a product manager of a real estate mobile app could explore how they could use GPT-4 to help its customers (realtors) write property listings:</p>

<figure class="figure">

    

    

    

    
        <img src="../images/prompt-engineering-real-estate-listing.png" alt="GPT-4 prompt engineering for real estate application" style="border-radius: 20px; max-width: 100%" srcset="../images/prompt-engineering-real-estate-listing.png 2x%" />
        <figcaption></figcaption>
        

</figure>

<p><strong>Prompt chaining</strong> is another important skill for generative AI. With prompt chaining, you ask the model a sequence of questions or provide a series of prompts to get additional information or closer to the answer you want from the model. For example, if the model’s initial output isn’t in the format you need it, you’ll need to “chain” prompts together to get the output in the right format. (In the example below, see how the user requested that the model only respond with the home type.)</p>

<p>For example, the same real estate mobile app mentioned above could use generative AI to fill in all of the property fields for a listing by providing the high-level property details as the original prompt. By chaining together multiple prompts, the developer could have the LLM produce all the outputs it needs for each listing. See <a href="https://chat.openai.com/share/ade82814-d867-4902-87f8-fe6a2cd37f7f">an example chat transcript from ChatGPT</a> for how this might look.</p>

<figure class="figure">

    

    

    

    
        <img src="../images/prompt-chaining-real-estate-listing2.png" alt="Prompt chaining with GPT-4" style="border-radius: 20px; max-width: 100%" srcset="../images/prompt-chaining-real-estate-listing2.png 2x%" />
        <figcaption>Prompt chaining with GPT-4</figcaption>
        

</figure>

<h2 id="what-is-discriminative-ai">What is discriminative AI?</h2>

<p>Now let’s shift to discriminative AI, which is the type of solution that Nyckel provides. The objective of discriminative AI is to make a decision or distinguish between different types of data. These models learn the boundaries between different classes or categories in the training data and then make predictions (or decisions) based on them. One of the most commonly used forms of discriminative AI are spam filters: Is this “spam” or “not spam?”</p>

<p>Typically, generative AI and discriminative AI are used for different situations altogether. However, you can use generative AI models/LLMs for discriminative tasks (including a spam filter). We shared an example of <a href="https://www.nyckel.com/blog/why-narrow-ai-is-better-than-gpt-4-for-machine-learning-driven-decisions/">how you could use GPT-4 for a discriminative task in this post</a>, showing how you could categorize an input as toxic or not toxic. </p>

<figure class="figure">

    

    

    

    
        <img src="../images/Nyckel-AI-approach-relating-to-GPT-4-2.png" alt="The confusion matrix for the whale sound classification function" style="border-radius: 20px; max-width: 80%" srcset="../images/Nyckel-AI-approach-relating-to-GPT-4-2.png 2x%" />
        <figcaption></figcaption>
        

</figure>

<p>However, when you need to complete a discriminative task (i.e., you need to make a decision), it’s often a lot faster to train a discriminative function. Plus, they scale much better because it’s easier to add more outputs and more data, while also tracking how well the function performs.</p>

<p>Compared to generative AI, the downside of discriminative AI solutions is that they’re narrower in focus. In other words, they’re trained to complete specific tasks, like detect objects, classify images, search text, and more. As a result, you can’t perform as many tasks as you can with generative AI. However, this is only relevant if your use case is something you can’t manage with a discriminative function. The narrow scope is actually an upside if discriminative AI is what you need (again, because it’s faster and easier to scale).</p>

<h3 id="discriminative-ai-skills">Discriminative AI skills</h3>

<p>When you’re using a discriminative AI solution, the most important activities your team needs to do, include: </p>

<ul>
  <li><strong>Choosing the right data as inputs.</strong> The data you use to train your model needs to be real-world data from your system and have enough annotated examples from each label set to train the model with. </li>
  <li><strong>Choose the right set of outputs.</strong> The output labels you choose will depend on what you’re trying to achieve with your discriminative function. For example, if you want to label your product images by the category they belong to on your website (e.g., <a href="https://www.rei.com">REI might label its products</a> by “Camp &amp; Hike,” “Climb,” “Cycle,” etc.), you will want to include all the relevant labels and decide <a href="https://www.nyckel.com/blog/multi-class-classification-vs-multi-label-classification-key-differences-how-to-choose/">whether a product image should only belong to one label or if it could have multiple labels assigned</a>.</li>
  <li><strong>Chain together simpler functions to a more complex whole.</strong> For example, let’s go back to the real estate management app. Imagine the site auto-tags photos by which room they are taken in. This can be done by training a “WhichRoomIsThis” multi-class classification function. However, before tagging photos with which room they are, you may want to add a “pre-processing” function that simply says “is this photo relevant for the posting?” That function could filter out blurry photos, personal photos, and other non-relevant images. So, you end up chaining together the “IsThisPhotoRelevant” function with the “WhichRoomIsThis” function.</li>
  <li><strong>Moderate decisions with low confidence and feed new annotated data into the model to improve performance.</strong> The most significant benefit to using a discriminative AI solution for discriminative tasks is the ability to monitor model performance and iterate on your data. Using a <a href="https://www.nyckel.com/blog/why-narrow-ai-is-better-than-gpt-4-for-machine-learning-driven-decisions/">discriminative solution that enables a data engine</a> helps you pinpoint where your model is underperforming and annotate new data to ensure the model receives the right kinds of inputs to increase performance. </li>
</ul>

<p>Here’s an example of how the same real estate mobile app could design a discriminative function to categorize listing photos into their respective categories:</p>

<p><strong>Input data</strong>: Images from a listing of a house for sale</p>

<p><strong>Output labels:</strong> Front exterior, Back exterior, Yard, Entryway, Kitchen, Dining Room, Living Room, Family Room, Sunroom, Office, Bedroom, ½ Bath, ¾ Bath, Full Bath, Closet, Mudroom, Stairway, Basement, Workout Room, Storage Space, Mechanical Room, Neighborhood Amenity, Neighborhood Park</p>

<p>If the real estate app wanted to separate interior versus exterior photos from each other, they could chain together different functions to break down the listing photos into smaller subsets: </p>

<ol>
  <li>Is this photo of the exterior or interior of a house?</li>
  <li>If exterior → is it: Front exterior, Back exterior, Yard, Neighborhood Amenity, Neighborhood Park?</li>
  <li>If interior → is it: Entryway, Kitchen, Dining Room, Living Room, Family Room, Sunroom, Office, Bedroom, ½ Bath, ¾ Bath, Full Bath, Closet, Mudroom, Stairway, Basement, Workout Room, Storage Space, Mechanical Room?</li>
</ol>

<figure class="figure">

    

    

    

    
        <img src="../images/discriminative-vs-generative-ai2.png" alt="Generative AI vs. Discriminative AI" style="border-radius: 20px; max-width: 100%" srcset="../images/discriminative-vs-generative-ai2.png 2x%" />
        <figcaption></figcaption>
        

</figure>

<h2 id="do-you-need-to-create-new-content-or-make-a-decision">Do you need to create new content or make a decision?</h2>

<p>Chances are you’ll be in a meeting soon when someone broaches the topic of how to integrate AI in your product. During those conversations, we challenge you to get to the bottom of what you’re trying to accomplish with AI. For example, are you trying to automate a process? Help a customer find what they’re looking for quicker? Integrate a supportive AI chatbot that can respond to customer inquiries?</p>

<p>The crux of this question is whether you need to classify existing data to help your product make a decision, or generate entirely new content.</p>

<p>Once you have a solid understanding of this, you can begin to narrow in on the segment of the AI market that can best solve your challenge. Popular LLMs like GPT-4 can perform discriminative tasks, <a href="https://www.nyckel.com/blog/why-narrow-ai-is-better-than-gpt-4-for-machine-learning-driven-decisions/">but not as well as narrow AI models trained to make decisions</a> (discriminative models). Understanding the difference between these different types of models is one of the first steps to effectively building AI into your product. </p>

<p>If discriminative AI is what you need, <a href="https://www.nyckel.com/console">give Nyckel a try for free</a>. If you need help getting started, <a href="https://www.nyckel.com/docs/image-classification-quickstart">check out our quickstarts</a> or <a href="mailto:feedback@nyckel.com">reach out to us</a>.</p>
:ET