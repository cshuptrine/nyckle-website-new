I"<h2 id="what-can-you-do-when-your-online-community-outgrows-your-content-moderation-capacity">What can you do when your online community outgrows your content moderation capacity?</h2>

<p>If you’re like most community managers the first time they’re confronted by spam, scams and hate speech in their user-generated content (UGC), you write a comprehensive list of naughty words and then use the list to automatically snag potentially harmful content in real time. This is much more efficient than tasking human moderators with trawling through every comment manually in order to moderate content, but, unlike human review, it’s a blunt instrument. It produces false positives by flagging innocent content that uses one of your banned words in a benign way that you didn’t anticipate. And it produces false negatives by letting through variant spellings of abusive terms, as well as all the latest vernacular innovations that are so numerous and diverse that it would be a full-time job just to keep up with them.</p>
:ET